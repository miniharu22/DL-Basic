{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea59c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03752320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28])\n",
      "torch.Size([60000])\n",
      "torch.Size([10000, 1, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# Download & Preprocess Dataset \n",
    "mnist= fetch_openml('mnist_784')\n",
    "\n",
    "# Set GPU Device\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Set the first 60,000 out of 70,000 as Train data\n",
    "X_train = torch.tensor(np.array(mnist.data)).float().reshape(-1, 1, 28, 28)[:60000].to(device)\n",
    "Y_train = torch.tensor(np.array(list(map(np.int_, mnist.target))))[:60000].to(device)\n",
    "\n",
    "# Set the last 10,000 out of 70,000 as Test data\n",
    "X_test = torch.tensor(np.array(mnist.data)).float().reshape(-1, 1 ,28, 28)[60000:].to(device)\n",
    "Y_test = torch.tensor(np.array(list(map(np.int_, mnist.target))))[60000:].to(device)\n",
    "\n",
    "print(X_train.shape) # torch.Size([60000, 1, 28, 28])\n",
    "print(Y_train.shape) # torch.Size([60000])\n",
    "\n",
    "print(X_test.shape) # torch.Size([10000, 1, 28, 28])\n",
    "print(Y_test.shape) # torch.Size([10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848725ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isang\\AppData\\Local\\Temp\\ipykernel_42384\\997699111.py:32: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  original = np.array(img_example).reshape(-1, 28).astype(int)\n",
      "C:\\Users\\isang\\AppData\\Local\\Temp\\ipykernel_42384\\997699111.py:33: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  aug_img = np.array(cutout_and_rotate(img_example)).reshape(-1, 28).astype(int)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAADOCAYAAABYf0t/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEz5JREFUeJzt3QdwVFW8x/ETgvQSivQmOIPSBGlSBIGh1wAWGAZEZGAQwQYOIF0QpaiAaFBEQWQYHBVEEKQEFJAOM0oZaSIaBAOhJBSB++Z/3tu8zZ4bzk3YDcnm+5lhMvyzu/fuzdnfPfecs7sRjuM4CgCQqhyp/woAIAhKALAgKAHAgqAEAAuCEgAsCEoAsCAoAcCCoAQAC4ISACwISj+fffaZioiIUCdPnkzzfWNjY/V95WcoyTYmTJgQ0m0AoXDy5EndfuV1ltUQlACSHTx4UJ+I09NZ8Pnyyy/Ve++9p8JJBO/1/n+3bt1S//33n8qdO7c+86XF7du31Y0bN1SuXLlUjhyhO//Ifo0fP55eJULiq6++Uk8++aTatGmTeuKJJ9L1GJ06dVK//vqrEbYSNdevX1f33XefioyMVFkJPUqlVGJiov4pf7w8efKkOSSFhKPcN5QhCWRlERER+jWS1UJShN2ret++fap9+/aqUKFCqkCBAqpVq1bql19+McYhN2/erIYMGaJKlCihypUrl+J3/mdC6SlK761MmTIqX758qkWLFvrypFKlSurZZ5+94xilnJFr1Kihby/3k/uXLVtWvfPOOyn2WXqi48aNU3Xr1lWFCxdW+fPnV48//rg+qyO0/vjjD90OqlatqvLmzauKFSume1SBvSFpA24n0LtpM777/vzzz2rYsGHq/vvvV1FRUWrQoEG6TSQkJKi+ffuqIkWK6H8jR47UvTJ/si25zK1evboOoZIlS+r7X7hwIcXtZNvS05NtNWjQQN+2cuXKatGiRSn2R567kH2WffNv0ytWrFAdO3bUz0uuuqpUqaImT56sr8T82/z333+vj6vv/rLtO41Rbty4Ubd3affy/Lt27aoOHTrkevyPHj2qj6HcTl4r/fv3V0lJSSrUcqow8ttvv+kDLiEpjUq6+DExMfqPJ8HYsGHD5NvKi0MapgSUr0fpZtSoUTrYOnfurNq2basOHDigf167ds3TPkmDbdeunerevbt66qmn9KXN66+/rmrWrKkDXVy6dEl98sknqlevXmrgwIHq8uXLasGCBXo7O3fuVLVr1w7C0YGbXbt2qW3btqlnnnlGnzDlxfzhhx/qNiPhJkGXVmltMy+++KIqVaqUmjhxoj6pz58/XweB7FeFChXU1KlT1erVq9X06dP1iVfC00dCUYJHAkPC9sSJE2ru3Lm6w7B161b9GvCRkOnZs6caMGCA6tevn/r000916MgJWoK2WbNm+jFmz56tRo8erR5++GF9v4f/76dsRzofr7zyiv4pASevH2m/sm9izJgx6uLFi+r06dPq3Xff1TW5bWrWr1+vXwcS2hKGV69eVXPmzFFNmjRRe/fuTQ5ZH3kNPfDAA+qtt97Sv5fXjXR23n77bRVSThjp1q2bkytXLufYsWPJtb///tspWLCg06xZM/3/hQsXyinZadq0qXPz5s0U9/f97sSJE/r/Z86ccXLmzKkf19+ECRP07fr165dc27Rpk67JT5/mzZvr2qJFi5Jr169fd0qVKuX06NEjuSb7IXV/Fy5ccEqWLOk899xzKeryeOPHj0/3MUJKSUlJRm379u3G302OudvL5W7ajO++bdu2dW7fvp1cb9SokRMREeEMHjw4RRspV66cblM+P/30k77/kiVLUmzrhx9+MOoVK1bUtS1btiTXzp496+TOndt59dVXk2vLly832vGdjtWgQYOcfPnyOdeuXUuudezYUW8vkBwjeWx53j61a9d2SpQo4cTHxyfXDhw44OTIkcPp27evcfwDXw/R0dFOsWLFnFALm0tv6f6vW7dOdevWTZ+dfEqXLq169+6tLznkzOcjPTfbWMmGDRvUzZs3de8zsAfglZxN+/Tpk/x/meyRS5/jx48n12Q/pO67lDp//rzebr169fRZE6Ejl9s+MpEXHx+vHnzwQd2jS8+xT0+bkR6e/2W9XPnIOVHq/m1E2oN/u1m+fLm+/GzdurX6999/k/9JD1HaXeDQTbVq1fQVl49cUcmQg/9jej1Wly9f1tuSx5NL38OHD6u0iouLU/v379e92qJFiybXa9WqpZ+T9KIDDR48OMX/ZfvyN/N/bYdC2ATluXPn9B9M/vCB5NJBAujPP/9Mrkn33UbGWYS8cPzJH1XGjLyQy7nAsS25b+AY0ueff64biIwdyTiZNGIZ65HLGISOXOrJ5WP58uX1uFvx4sX1sZfxwfQc+/S0Gbm89ifhJ2SfAuv+7eb333/X+yiXnrLP/v+uXLmizp49e8ftpNYW7zS0FR0drfdDhrdkO75OwN0cq9ResxLEgcNigc/Bd0y9Pof0CqsxyrTwPzuGUmq9Vv9B+S+++EKfVaU3PGLECN3w5X4yDnPs2LEM2c/sSnp6CxcuVC+99JJq1KiRDgE5scmYpZxcfVJbCeE/kRHsNuJW9283sn/SVpYsWeJ6fwkyL9vxskIwISFBNW/eXAfkpEmT9ESOnNSl1y1j7v7HKpTu5jncjbAJSmkUMvB+5MgR43dyWSDLduQMLYP3XlWsWDF5ENy/Bypd/WCewWSCR4YLvv766xQvSFkvidCSYy8TGzNnzkyuyaSLBINbz0Xqclke2CvK6DYjJKxkMkQmPoJ14k/thBAbG6ufg7RRmfTxkckjr48RyHesUnvNSu9eZsIzg7C59JYzTZs2bfQSBv+lGv/8849+p0DTpk312TAtZGlRzpw59SyoP5lVDMVZ0v+suGPHDrV9+/agbgfuxz6wNyKzroE9RQklsWXLluSaXBbKkMm9aDO+GWDZT1miE0jGSQPD3gtfMAXeN9KljcoSpnnz5rk+hpdLcZk/kBUdcgz9tyeL1WW+oUOHDiqzCJsepXjzzTfVjz/+qENRBtOlwcryIHk3QODaRS9kTdrw4cN1b6NLly56mY8s9VizZo0+26VnYbobWd8mZ2oZ/5F1anKW/uijj/Tgu4w1IXTk2C9evFhfcsvxlpOT9NJknNifnIRlfEwmWGR4RIJDltfIlcypU6cyvM0IuRSW5UEyRCOTIrKPshxIxi5louf999/Xy4HSQoJLnpsst5Gwk3Hbli1bqsaNG+tetfS+ZQmRPA85bm6XvDKZtGzZMr2MqH79+npiSZZKuZFlRbI8SIY95Nj6lgfJ3yNTvfvMCTN79+7Vyy0KFCigly20aNHC2bZtm7EkY9euXdalHr5lGWPHjtVLevLmzeu0bNnSOXTokF6S4L98I7XlQdWrVze2I0tE/JdPyNKQqVOn6pos16hTp46zatUq43aC5UHBJcuw+vfv7xQvXly3GWk7hw8f1sfdfymP2LNnj9OwYUO9BK1ChQrOrFmz7qrNpNYWfUthzp07l6Iu+5M/f37jOcyfP9+pW7eu3pYshatZs6YzcuRIvTTOR56PLNsJJG3Uf8mR+Pjjj53KlSs7kZGRKdr01q1bnccee0xvp0yZMnoba9euNdr9lStXnN69eztRUVH6d7427LY8SKxfv95p0qSJftxChQo5nTt3dg4ePOjpmLgd/1Dgvd7pIJcJcnaVHqwssAVsaDNZW9iMUYaKXAoE8n0ySno/NADhjTYTfsJqjDIUZKxF3rolA8sy1iIL15cuXarHg2S2EQhEmwk/BKWFLAKXSSGZDJLV/77BermEAtzQZsIPY5QAYMEYJQBYEJQAYEFQAoAFQQkAFgQlAFgQlABgQVACgAVBCQAWBCUAWBCUAGBBUAKABUEJABYEJQBYEJQAYEFQAoAFQQkAFgQlAFgQlABgQVACgAVBCQAWBCUAWBCUAGBBUAKABUEJABYEJQBYEJQAYJFTeRQREeH1poDmOE6Gbo82ilC1UXqUAGBBUAKABUEJABYEJQBYEJQAYEFQAoAFQQkAFgQlAFgQlABgQVACgAVBCQAWBCUAWBCUAGBBUAKABUEJABYEJQBYEJQAYEFQAoAFQQkAwfrOHABKjR8/3qht3rzZqMXGxmbQHiEj0KMEAAuCEgAsCEoAsCAoAcAiwvH4DeDZ7cvlIyMjjVrhwoXv6jGHDh1q1PLly2fUqlatatReeOEFozZjxgyj1qtXL6N27do1ozZt2jSjNnHiRHUvvlw+WDKijV69etWo7d6926g9//zzRu3IkSMh2y+Eto3SowQAC4ISACwISgCwICgBILu8M6dChQpGLVeuXEatcePGRq1p06ZGLSoqyqj16NFDZYTTp08btdmzZxu16Ohoo3b58mWjduDAAU/vJoFdnjx5jNojjzxi1IoUKZJBe4SMQI8SACwISgCwICgBwIKgBIBwnMypXbu2Udu4cWPQ30mTEW7fvm3U3njjDaN25coVo7ZkyRKjFhcXZ9QuXLhg1HiXSPosXbrUqD399NNGrXTp0un+2LasYPLkyZ7acrigRwkAFgQlAFgQlABgQVACQDhO5pw6dcqoxcfH35PJnB07drjWExISjFqLFi2M2o0bN4za4sWLg7R3CLbXXnvN0zvAwt2ePXs8TSR26NBBhQN6lABgQVACgAVBCQAWBCUAhONkzvnz543aiBEjjFqnTp2M2r59+zx9hJmb/fv3G7XWrVu73jYxMdGoVa9e3agNHz7c07aROXzwwQdG7dFHHzVqK1asUOGsVq1antp3ly5djNrKlStVVkOPEgAsCEoAsCAoAcCCoAQAiwjH4zeAZ8SXywdboUKFPH2nTExMjFEbMGCAUevTp4+nj91C2r5cPlgyoo1OmzbN00Si20eOJSUlGbVZs2aprGjcuHGebrd7926j1qhRo0zzEW1e2yg9SgCwICgBwIKgBAALghIAwvGdOV5dunTJ0+0uXrzo6XYDBw40asuWLXO9bTh/f0h25jYh4yZHjhxh/XFs69atM2pt2rQxavXq1TNqXbt2NWrffPONyszoUQKABUEJABYEJQBYEJQAkJ3fmeNV/vz5jdp3331n1Jo3b27U2rdv73mwO7sJx3fmFC1a1KidO3fO033Xrl3r+TuXMrvIyEijNmbMGE/3dXvOrVq1MmpXr15VocY7cwAgSAhKALAgKAHAgqAEAAsmc1JRpUoVo7Z3716jlpCQ4Hr/TZs2efrIKbfvYMnoSZBQYTLHPonhNsGTFXzj8k6aNWvWGLVSpUp5erwePXoYtW+//VaFGpM5ABAkBCUAWBCUAGBBUAKABZM5aRAdHW3UFi5c6HrbggULenrM0aNHG7VFixYZtbi4OJXVMJljN2nSJJUVTZw40ajNmTPHqA0ZMsTT423bts2otWvXzqglJiaqYGIyBwCChKAEAAuCEgAsCEoAsCAoAcCCWe+7VKNGDdf6rFmzPH3mnpuYmBijNmXKFKP2119/qcwsHGe93T6HcenSpZ7ekhfus95Vq1Y1aqtXrzZqlSpV8rSNadOmpfszL71i1hsAgoSgBAALghIALAhKALBgMidEoqKijFrnzp09vQXS7Vhv3LjRqLVu3VplZuE4meNm/vz5Rm3AgAHpfrwFCxYYtYsXLxq1CRMmhPwtfnfr5ZdfNmozZszwdN+kpCSjVr58ec+fCesFkzkAECQEJQBYEJQAYEFQAoAFkzn32PXr141azpw5jdrNmzeNWtu2bY1abGysyiyyy2RO3759PX9OaaBhw4YZtXnz5oXNF86VcvlysQ0bNhi1hx56yNPjTZ061aiNHTs2nXvHZA4ABA1BCQAWBCUAWBCUAGBhzhogTWrVquVa79mzp1GrX7++p4kbNwcPHjRqW7Zs8XRfhJbbF2N5VadOHU9fTHfp0iWVFZ05c8aoDR061KitX7/e0+N5fb0EGz1KALAgKAHAgqAEAAuCEgAsmMxJhdv3f7gNQnfv3t3zOxK8unXrllGLi4szardv3073NhA8N27c8PSxaPHx8UZt1apVYTNx45XbxOTx48eNWuXKlY1ap06djNqoUaNUqNGjBAALghIALAhKALAgKAHAItt9zJrbJEuvXr08Tdx4/eL2tNi9e7dRmzJlilFbuXKlymqyy8esualdu7ZRO3XqlFE7f/58Bu1R5rZ8+XLPE6WBIiMj071dPmYNAIKEoAQAC4ISACwISgDILpM5JUuWNGrVqlUzanPnzk3393WkxY4dO4za9OnTjdqKFSvC9h032XkyB2lTtGhRo7Z//36jVrZsWaPGZA4AZAIEJQBYEJQAYEFQAkBW/5g1t0HemJgYT++EcPuYpmB/N8rMmTNdb7t27VqjdvXq1aDuDxAuzru8Q2nnzp1GLTo6Wt0L9CgBwIKgBAALghIALAhKAMiskzkNGzY0aiNGjDBqDRo08LQ6/24kJSUZtdmzZxu1qVOnGrXExMSg7guA1N/JdvToUXUv0KMEAAuCEgAsCEoAsCAoASCzfszatGnTPE3m3M2Xqrt9ufzNmzc9vbsmISEh3fuC/8XHrCGz42PWACBICEoAsCAoAcCCoASA7PKdOch8mMxBZsdkDgAECUEJABYEJQBYEJQAYEFQAoAFQQkAFgQlAFgQlABgQVACgAVBCQAWBCUAWBCUAGBBUAKABUEJAMH6mDUAyK7oUQKABUEJABYEJQBYEJQAYEFQAoAFQQkAFgQlAFgQlABgQVACgLqz/wHs688Z7U8S8wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 400x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "def cutout_and_rotate(image):\n",
    "    image = image.clone().detach() \n",
    "    x_start = np.random.randint(20)     # Cut- out x-axis position to start (1 of 0-19)\n",
    "    y_start = np.random.randint(20)     # Cut- out y-axis position to start (1 of 0-19)\n",
    "\n",
    "    # Gray marking on the corresponding part\n",
    "    image[..., x_start:x_start+9, y_start:y_start+9] = 255/2\n",
    "    # 90 degree rotation based on the last two axis\n",
    "    return torch.rot90(image, 1, [-2, -1])\n",
    "\n",
    "# Test Case fot Data Augmentation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import style\n",
    "\n",
    "# Specify whit background & its size  \n",
    "style.use('default')\n",
    "figure = plt.figure()\n",
    "figure.set_size_inches(4, 2)\n",
    "\n",
    "# Set the style for black & white print\n",
    "style.use('grayscale')\n",
    "\n",
    "# 1x2 size grid setting\n",
    "axes = []\n",
    "for i in range(1,3):\n",
    "    axes.append(figure.add_subplot(1, 2, i))\n",
    "\n",
    "# Visulization of the original Image\n",
    "# Visulization of the image performed by augmentation fot the first image\n",
    "img_example = X_train[0].clone().detach().cpu()\n",
    "original = np.array(img_example).reshape(-1, 28).astype(int)\n",
    "aug_img = np.array(cutout_and_rotate(img_example)).reshape(-1, 28).astype(int)\n",
    "\n",
    "axes[0].matshow(original)\n",
    "axes[1].matshow(aug_img)\n",
    "\n",
    "axes[0].set_axis_off()\n",
    "axes[0].set_title('original')\n",
    "axes[1].set_axis_off() \n",
    "axes[1].set_title('augmentation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b63b65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing CNN Model Structure\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride= 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, stride= 1)\n",
    "        self.fc = nn.Linear(4 * 4 * 20, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch, 1, 28, 28) -> (batch, 10, 24, 24)\n",
    "        x = F.relu(self.conv1(x)) \n",
    "        # (batch, 10, 24, 24) -> (batch, 10, 12, 12)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
    "        # (batch, 10, 12, 12) -> (batch, 20, 8, 8)\n",
    "        x = F.relu(self.conv2(x)) \n",
    "        # (batch, 20, 8, 8) -> (batch, 20, 4, 4)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
    "        # (batch, 20, 4, 4) -> (batch, 320)\n",
    "        x = x.view(-1, 4 * 4 * 20) \n",
    "        # (batch, 320) -> (batch, 100)\n",
    "        x = F.relu(self.fc(x)) \n",
    "        # (batch, 100)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90177af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Loss Function\n",
    "class SimCLR_Loss(nn.Module):\n",
    "    def __init__(self, batch_size, temperature):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.mask = self.mask_correlated_samples(batch_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    # masking matrix to import only the internal sum\n",
    "        # between the negative samples of the loss denominator part\n",
    "    def mask_correlated_samples(self, batch_size):\n",
    "        N = 2 * batch_size\n",
    "        mask = torch.ones((N, N), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            mask[i, batch_size + i] = 0\n",
    "            mask[batch_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "\n",
    "        N = 2 * self.batch_size\n",
    "\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "\n",
    "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n",
    "\n",
    "        # The source of the loss molecule part\n",
    "        # The part to get the internal sum between the augmentation images\n",
    "        sim_i_j = torch.diag(sim, self.batch_size)\n",
    "        sim_j_i = torch.diag(sim, -self.batch_size)\n",
    "        \n",
    "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
    "        negative_samples = sim[self.mask].reshape(N, -1)\n",
    "        \n",
    "        labels = torch.from_numpy(np.array([0]*N)).reshape(-1).to(positive_samples.device).long()\n",
    "        \n",
    "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= N\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a78e0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaf5536fa7e4f9bb06409cb845499be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Avg Loss : 3.0187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51eaca3d7ca747c7ac8b6bbbe4a0074c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Avg Loss : 2.7996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4e659346b54f7b85a05c713ca6dce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3, Avg Loss : 2.7614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47ceae273ab454cb71c11bbfe80461b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, Avg Loss : 2.7169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229d776d2e0b44f4af95de2985bf17f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5, Avg Loss : 2.6954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578d82043bdf4d0e9c111e8f90d5a7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6, Avg Loss : 2.6813\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3775ba6e610426bae004ced5e91f4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7, Avg Loss : 2.6652\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdff69e53c44266b728a4e9ebc38365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8, Avg Loss : 2.6564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7984fb5467aa43ba83a928076340e0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9, Avg Loss : 2.6507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb392f521f54135b2b3f109ea0b0601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10, Avg Loss : 2.6429\n"
     ]
    }
   ],
   "source": [
    "# Pre-train\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Augmentation for each X_train data\n",
    "X_train_aug = cutout_and_rotate(X_train) \n",
    "# Declare to GPU for Learning\n",
    "X_train_aug = X_train_aug.to(device) \n",
    "\n",
    "# Pair with Augmentation data\n",
    "dataset = TensorDataset(X_train, X_train_aug) \n",
    "batch_size = 32\n",
    "\n",
    "dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size = batch_size)\n",
    "\n",
    "# Declare Model variable\n",
    "model = CNN() \n",
    "# Declare Loss Function\n",
    "loss_func = SimCLR_Loss(batch_size, temperature = 0.5) \n",
    "\n",
    "# training\n",
    "epochs = 10\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for i in range(1, epochs + 1):\n",
    "    total_loss = 0\n",
    "    for data in tqdm(dataloader):\n",
    "        origin_vec = model(data[0])\n",
    "        aug_vec = model(data[1])\n",
    "\n",
    "        loss = loss_func(origin_vec, aug_vec)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch : %d, Avg Loss : %.4f'%(i, total_loss / len(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e7371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8b48cef75a4cf7aa48e6fc8f3e4ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Accuracy : 69.58%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d137e009db5b498d916ad46a3740be1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Train Accuracy : 93.64%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3a8d4c4c54429d9406df7f6824c5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3, Train Accuracy : 95.92%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158e085eb7d849a1813a513db6ae1154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, Train Accuracy : 96.86%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72badc798374460b15aafc28b88fc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5, Train Accuracy : 97.40%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de2942a97c24cc882b8513eb889d4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6, Train Accuracy : 97.78%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5053e23d8f8a4cc7a8fa8f1c8a5833eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7, Train Accuracy : 98.09%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c90dd99449a48bd807465f1c482bbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8, Train Accuracy : 98.31%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b2ec4afdfe4b7cacd19352d50d4ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9, Train Accuracy : 98.48%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92347e9534964ec69601b7b88839211c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10, Train Accuracy : 98.61%\n"
     ]
    }
   ],
   "source": [
    "# Downstream model for Classification\n",
    "class CNN_classifier(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        # Load model trained with Constrastive Learning\n",
    "        self.CNN = model \n",
    "        # Projection by the number of class dimensions\n",
    "        self.mlp = nn.Linear(100, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.CNN(x) # Convert to (batch, 100)\n",
    "        x = self.mlp(x) # Convert to (batch, 10)\n",
    "        return x # (batch, 10)\n",
    "\n",
    "# Pair with Data & Lable\n",
    "class_dataset = TensorDataset(X_train, Y_train)\n",
    "batch_size = 32\n",
    "\n",
    "class_dataloader = DataLoader(\n",
    "        class_dataset,\n",
    "        batch_size = batch_size)\n",
    "\n",
    "\n",
    "# Classification Downstream model Training\n",
    "classifier = CNN_classifier(model).to(device)\n",
    "classifier_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr= 1e-4)\n",
    "\n",
    "for i in range(1, epochs + 1):\n",
    "    correct = 0\n",
    "    for data in tqdm(class_dataloader):\n",
    "        logits = classifier(data[0])\n",
    "\n",
    "        loss = classifier_loss(logits, data[1].long())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate number of correct answers for Accuracy calculation\n",
    "        correct += torch.sum(torch.argmax(logits, 1) == data[1]).item() \n",
    "\n",
    "    print('Epoch : %d, Train Accuracy : %.2f%%'%(i, correct * 100 / len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405f4142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93641729a67f48cea60229f8f636ff4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 98.31%\n"
     ]
    }
   ],
   "source": [
    "# Verification with Test Data\n",
    "# pair with Test data & Label\n",
    "test_dataset = TensorDataset(X_test, Y_test) \n",
    "batch_size = 32\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size = batch_size)\n",
    "\n",
    "# Convert to Test mode\n",
    "classifier.eval() \n",
    "\n",
    "correct = 0\n",
    "for data in tqdm(test_dataloader):\n",
    "\n",
    "    logits = classifier(data[0])\n",
    "    # Accumulate number of correct answers for Accuracy calculation\n",
    "    correct += torch.sum(torch.argmax(logits, 1) == data[1]).item() \n",
    "\n",
    "print('Test Accuracy : %.2f%%'%(correct * 100 / len(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
