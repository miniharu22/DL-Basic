{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a47ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim, cuda\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# Training settings\n",
    "batch_size = 64\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'   # Use GPU if available, otherwise CPU\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Define fully connected layers\n",
    "        self.l1 = nn.Linear(784, 520)  # Input layer (28x28=784) to hidden layer\n",
    "        self.l2 = nn.Linear(520, 320)  # Hidden layer\n",
    "        self.l3 = nn.Linear(320, 240)  # Hidden layer\n",
    "        self.l4 = nn.Linear(240, 120)  # Hidden layer\n",
    "        self.l5 = nn.Linear(120, 10)   # Output layer (10 classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784)\n",
    "        x = F.relu(self.l1(x))  # Apply ReLU activation\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)       # Output logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853cff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = Net()\n",
    "model.to(device) # Move model to the appropriate device (CPU/GPU)\n",
    "criterion = nn.CrossEntropyLoss()   # Loss function for multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(),    # Adam optimizer\n",
    "                             lr=0.01, \n",
    "                             betas=(0.9, 0.999),\n",
    "                             eps=1e-08,\n",
    "                             weight_decay=0,\n",
    "                             amsgrad=False)\n",
    "\n",
    "# Training function\n",
    "def train(epoch):\n",
    "    model.train()   # Set the model to training mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Move data and target to the device\n",
    "        data, target = data.to(device), target.to(device)   \n",
    "        optimizer.zero_grad()               # Zero the gradients\n",
    "        output = model(data)                # Forward pass\n",
    "        loss = criterion(output, target)    # Compute loss\n",
    "        loss.backward()                     # Backward pass\n",
    "        optimizer.step()                    # Update weights\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def test():\n",
    "    model.eval()    # Set model to evaluation mode\n",
    "    test_loss = 0   # Initialize test loss\n",
    "    correct = 0     # Initialize correct predictions counter\n",
    "    for data, target in test_loader:\n",
    "        # Move data and target to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)                            # Forward pass\n",
    "        test_loss += criterion(output, target).item()   # Accumulate loss\n",
    "\n",
    "        # Get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]      \n",
    "        # Count correct predictions\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    # Average the test loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784f4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.304297\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 1.670444\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 0.762810\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 0.877331\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 0.819677\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 0.368655\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 0.649755\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 0.185701\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 0.272089\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 0.622051\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 0.344957\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 0.407387\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 0.273092\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 0.321562\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 0.682199\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 0.340676\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 0.663467\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 0.531135\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 0.124123\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 0.744089\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 0.288188\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 0.368774\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 0.287515\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 0.491106\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 0.248046\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 0.526175\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 0.285429\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 0.291717\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 0.329166\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 0.268546\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 0.132947\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 0.472271\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 0.445877\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 0.377124\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 0.233607\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 0.369957\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 0.294594\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 0.114753\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 0.100531\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 0.296892\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 0.210952\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 0.219716\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 0.254729\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 0.094553\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 0.121160\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 0.134568\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 0.213220\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 0.168101\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 0.286100\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 0.429920\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 0.314532\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 0.175921\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 0.143342\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 0.140632\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 0.261695\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 0.133839\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 0.142914\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 0.314771\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 0.089231\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 0.451640\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 0.157717\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 0.237988\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 0.434129\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 0.199372\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 0.444028\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 0.107325\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 0.125190\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 0.326059\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 0.129585\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 0.203629\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 0.203729\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 0.116320\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 0.282526\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 0.232908\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 0.267286\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 0.180843\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 0.011965\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 0.263740\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 0.586589\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 0.298429\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 0.287112\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 0.323517\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 0.253450\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 0.115914\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 0.038281\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 0.158622\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 0.260426\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 0.098510\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 0.126454\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 0.214437\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 0.222223\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 0.106759\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 0.206421\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 0.334528\n",
      "Training time: 0m 8s\n",
      "===========================\n",
      "Test set: Average loss: 0.0080, Accuracy: 9303/10000 (93%)\n",
      "Testing time: 0m 8s\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 0.977010\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 0.171398\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 0.147911\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 0.606422\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 0.108978\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 0.158670\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 0.207311\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 0.180748\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 0.106995\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 0.160788\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 0.450189\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 0.199183\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 0.365841\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 0.407913\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 0.217505\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.216277\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 0.158904\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.277386\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 0.260970\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.143667\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.210128\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.176830\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.150896\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.165135\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.145119\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.185743\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.191461\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.338501\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.098556\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.031083\n",
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.117091\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.113190\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.226179\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.229998\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.096773\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.064626\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.241027\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.026397\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.471881\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.133784\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.213872\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.209576\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.084899\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.115466\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.118715\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.176761\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.202592\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.399036\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.125955\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.177460\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.262465\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.098722\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.382450\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.277087\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.296315\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.078371\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.101974\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.449169\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.139690\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.137025\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.190399\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.094238\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.207484\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.191782\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.069789\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.130383\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.120647\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.070192\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.170617\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.079042\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.248223\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.090478\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.142481\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.057225\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.042235\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.087026\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.213395\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.189682\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.157376\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.104700\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.116606\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.190210\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.163642\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.078937\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.210737\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.181359\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.032548\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.115213\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.240709\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.275509\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.215427\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.093995\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.269944\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.113779\n",
      "Training time: 0m 8s\n",
      "===========================\n",
      "Test set: Average loss: 0.0027, Accuracy: 9555/10000 (96%)\n",
      "Testing time: 0m 8s\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.146684\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.055513\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.226246\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.046607\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.110893\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.027824\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.178047\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.061652\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.118617\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.054524\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.225118\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.099812\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.142161\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.497611\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.307506\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.093960\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.070248\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.318050\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.074849\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.487050\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.313052\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.190663\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.134990\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.692860\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.424582\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.086025\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.138316\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.274770\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.155780\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.218215\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.443551\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.176471\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.056393\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.216441\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.271706\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.041515\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.487020\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.495550\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.617292\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.163464\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.041460\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.239008\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.117295\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.370979\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.168382\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.187572\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.028566\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.232244\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.053556\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.227455\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.150094\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.084501\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.388035\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.190583\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.120098\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.100275\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.222364\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.136286\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.171285\n",
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.176658\n",
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.040539\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.119679\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.048401\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.252225\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.168668\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.136713\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.024546\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.135945\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.107916\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.057505\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.336525\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.041038\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.102507\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.017712\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.060262\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.314957\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.104112\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.208559\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.110947\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.126136\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.033816\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.157541\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.364934\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.210929\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.463036\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.202615\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.173325\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.290430\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.335010\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.247900\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.052558\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.573489\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.173455\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.798004\n",
      "Training time: 0m 8s\n",
      "===========================\n",
      "Test set: Average loss: 0.0040, Accuracy: 9537/10000 (95%)\n",
      "Testing time: 0m 8s\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.020893\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.064780\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.101292\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.086372\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.154952\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.053185\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.094977\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.197244\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.064176\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.237505\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.246525\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.092057\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.044860\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.142866\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.122337\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.070358\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.239668\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.041021\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.196131\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.125800\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.108067\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.179757\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.207834\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.198298\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.025073\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.283968\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.107884\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.330300\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.367798\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.039613\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.075303\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.448795\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.098034\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.191719\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.207820\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.129320\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.134922\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.131851\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.169946\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.158449\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.110107\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.182712\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.049635\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.103518\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.069241\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.082967\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.066465\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.046740\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.069618\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.193018\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.119518\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.109703\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.306646\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.132375\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.503522\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.259325\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.104922\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.243943\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.345155\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.098952\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.133217\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.313411\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.065263\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.172111\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.006364\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.104837\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.259341\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.350717\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.096607\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.013777\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.282389\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.129579\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.090218\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.170580\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.152031\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.104098\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.137320\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.059551\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.264119\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.289542\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.141542\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.206806\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.251048\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.277985\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.324482\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.039337\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.164419\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.243433\n",
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.121726\n",
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.093254\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.075389\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.385457\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.070404\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.249695\n",
      "Training time: 0m 9s\n",
      "===========================\n",
      "Test set: Average loss: 0.0025, Accuracy: 9644/10000 (96%)\n",
      "Testing time: 0m 9s\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.041963\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.106497\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.028215\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.075753\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.059779\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.086939\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.192973\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.280608\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.177586\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.044814\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.090572\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.309300\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.152464\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.037939\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.215118\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.275605\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.149621\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.170791\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.037232\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.052722\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.283773\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.236335\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.059434\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.283450\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.152494\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.067973\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.018969\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.059500\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.076925\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.128537\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.131712\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.203220\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.098245\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.111816\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.096022\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.060240\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.287698\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.097828\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.191580\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.054117\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.144046\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.131384\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.011727\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.056164\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.013077\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.103160\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.374625\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.125418\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.062532\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.043894\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.062775\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.007991\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.047481\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.025641\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.076317\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.266058\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.279610\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.036994\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.127034\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.086166\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.114263\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.072233\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.032127\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.180517\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.046488\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.006378\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.056171\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.159703\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.078571\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.235775\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.163576\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.024458\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.084241\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.090130\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.123473\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.205206\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.202203\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.143633\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.066895\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.081092\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.137343\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.007817\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.103268\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.147100\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.031610\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.280947\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.115409\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.207023\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.492722\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.093893\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.050911\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.043397\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.040215\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.020191\n",
      "Training time: 0m 8s\n",
      "===========================\n",
      "Test set: Average loss: 0.0025, Accuracy: 9639/10000 (96%)\n",
      "Testing time: 0m 9s\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.026882\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.168167\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.124572\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.157379\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.134856\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.145835\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.147454\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.035985\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.063344\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.145121\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.166401\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.012280\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.008065\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.076446\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.077781\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.132226\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.101845\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.035496\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.071121\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.030111\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.036567\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.087690\n",
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.018115\n",
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.045258\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.168580\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.080913\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.033446\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.049169\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.014408\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.053602\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.111540\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.090492\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.315830\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.113145\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.155556\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.047467\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.163706\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.074806\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.194352\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.217877\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.518025\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.147051\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.085439\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.116850\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.072800\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.044882\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.153669\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.081927\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.176208\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.086904\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.086820\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.027663\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.204331\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.015737\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.041042\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.100827\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.052358\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.140011\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.068025\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.324828\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.112728\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.050877\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.051504\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.093979\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.103710\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.123546\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.079320\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.109341\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.232005\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.032050\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.270614\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.135258\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.098556\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.093066\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.367154\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.248292\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.025306\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.093953\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.279193\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.078226\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.017073\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.051542\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.117554\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.091380\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.049768\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.062586\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.225293\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.191418\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.063978\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.077742\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.216243\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.062292\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.072887\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.083649\n",
      "Training time: 0m 8s\n",
      "===========================\n",
      "Test set: Average loss: 0.0032, Accuracy: 9563/10000 (96%)\n",
      "Testing time: 0m 9s\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.186135\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.089985\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.046161\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.190625\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.039800\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.911034\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.059630\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.121463\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.223227\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.269108\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.221133\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.059281\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.111772\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.140646\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.124983\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.114571\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.105316\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.132825\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.080061\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.376611\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.211152\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.037417\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.258111\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.090965\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.117500\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.049493\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.194686\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.089542\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.069896\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.041565\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.062178\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.126967\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.264316\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.169597\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.004853\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.079561\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.184091\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.210420\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.031380\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.075181\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.205312\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.177853\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.061131\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.014112\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.088434\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.109168\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.165410\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.062618\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.102065\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.155250\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.073634\n",
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.081773\n",
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.064929\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 1.041512\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.033291\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.134484\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.054804\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.078981\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.018331\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.212980\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.157350\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.122289\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.119909\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.135327\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.006406\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.110192\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.024499\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.182236\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.213086\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.153013\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.145874\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.057570\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.060091\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.224147\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.037083\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.591007\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.115842\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.140986\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.361992\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.064380\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.116790\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.481874\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.438932\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.327054\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.115964\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.405357\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.153671\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.207901\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.028491\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.169467\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.278356\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.141901\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.112722\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.269292\n",
      "Training time: 0m 14s\n",
      "===========================\n",
      "Test set: Average loss: 0.0041, Accuracy: 9454/10000 (95%)\n",
      "Testing time: 0m 16s\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.043767\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.132081\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.168564\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.060310\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.220799\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.205043\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.135347\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.244686\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.353723\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.151803\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.536549\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.275363\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.161563\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.333331\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.339057\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.306627\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.033465\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.207198\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.132689\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.074418\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.357807\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.061839\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.275403\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.230580\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.277277\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.179500\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.030988\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.146469\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.140935\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.137335\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.038469\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.022510\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.227490\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.066006\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.069566\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.036686\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.102073\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.009120\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.285172\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.201025\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.076734\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.081658\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.052395\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.094275\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.023997\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.130641\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.180878\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.066999\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.021029\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.184596\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.367932\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.207475\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.131761\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.330875\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.196790\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.103819\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.063137\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.059684\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.231189\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.103422\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.109446\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.314765\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.123435\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.132859\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.030164\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.008640\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.053613\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.110619\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.012926\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.134745\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.104456\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.074764\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.168740\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.088145\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.090894\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.036626\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.105526\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.009143\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.052908\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.030053\n",
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.059094\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.245603\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.089241\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.060066\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.162883\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.006471\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.127983\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.089362\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.081893\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.145833\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.084062\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.042743\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.022668\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.107172\n",
      "Training time: 0m 17s\n",
      "===========================\n",
      "Test set: Average loss: 0.0026, Accuracy: 9706/10000 (97%)\n",
      "Testing time: 0m 18s\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.027296\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.062471\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.087804\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.167566\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.005214\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.116842\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.195860\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.091805\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.088793\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.089513\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.032172\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.089495\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.055603\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.068936\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.078585\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.328079\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.096441\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.168634\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.111172\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.248341\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.003141\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.011957\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.067175\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.024936\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.065610\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.072704\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.128293\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.041626\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.204601\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.092003\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.202502\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.039013\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.081596\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.093690\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 1.098467\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.108776\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.058826\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.108893\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.134908\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.087808\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.243869\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.013690\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.133129\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.070238\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.302339\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.173742\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.202112\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.128833\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.036725\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.029826\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.224675\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.052495\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.284712\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.099832\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.063220\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.080521\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.153359\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.009358\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.228071\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.112091\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.148001\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.118372\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.122771\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.012678\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.102171\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.079472\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.059703\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.076598\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.197542\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.007786\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.278409\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.036202\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.052245\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.039595\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.218733\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.449770\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.149913\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.243539\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.181211\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.260183\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.294743\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.142975\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.181287\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.153238\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.135751\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.244777\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.097075\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.074011\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.079670\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.099438\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.215288\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.151255\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.120654\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.262321\n",
      "Training time: 0m 17s\n",
      "===========================\n",
      "Test set: Average loss: 0.0033, Accuracy: 9640/10000 (96%)\n",
      "Testing time: 0m 18s\n",
      "Total Time: 1m 44s\n",
      "Model was trained on cpu!\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "if __name__ == '__main__':\n",
    "    since = time.time()\n",
    "    for epoch in range(1, 10):\n",
    "        epoch_start = time.time()\n",
    "        train(epoch)\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
    "        test()\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
    "\n",
    "    m, s = divmod(time.time() - since, 60)\n",
    "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
