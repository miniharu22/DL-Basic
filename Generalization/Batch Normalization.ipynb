{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d076d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim, cuda\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Training settings\n",
    "batch_size = 64\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'   # Use GPU if available, otherwise CPU\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "sample_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bed4a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, use_batchnorm=False):\n",
    "        super(Net, self).__init__()\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.batchnorms = nn.ModuleList()\n",
    "        \n",
    "        layer_sizes = [784] + [64] * 10\n",
    "\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "            self.batchnorms.append(\n",
    "                nn.BatchNorm1d(layer_sizes[i + 1]) if use_batchnorm else nn.Identity()\n",
    "            )\n",
    "\n",
    "        self.output = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = x.view(-1, 784)\n",
    "        features = []\n",
    "\n",
    "        for layer, bn in zip(self.hidden_layers, self.batchnorms):\n",
    "            x = F.relu(bn(layer(x)))\n",
    "            if return_features:\n",
    "                features.append(x)\n",
    "\n",
    "        out = self.output(x)\n",
    "        if return_features:\n",
    "            return out, features\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75607858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, optimizer, criterion, epoch):\n",
    "    model.train()   # Set the model to training mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Move data and target to the device\n",
    "        data, target = data.to(device), target.to(device)   \n",
    "        optimizer.zero_grad()               # Zero the gradients\n",
    "        output = model(data)                # Forward pass\n",
    "        loss = criterion(output, target)    # Compute loss\n",
    "        loss.backward()                     # Backward pass\n",
    "        optimizer.step()                    # Update weights\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                batch_idx * len(data), \n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24b84aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def test(model, criterion):\n",
    "    model.eval()    # Set model to evaluation mode\n",
    "    test_loss = 0   # Initialize test loss\n",
    "    correct = 0     # Initialize correct predictions counter\n",
    "    for data, target in test_loader:\n",
    "        # Move data and target to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)                            # Forward pass\n",
    "        test_loss += criterion(output, target).item()   # Accumulate loss\n",
    "\n",
    "        # Get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]      \n",
    "        # Count correct predictions\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    # Average the test loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5900e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Visulization function  \n",
    "def visualize_features(model, image_tensor, label, title_prefix):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, features = model(image_tensor.unsqueeze(0).to(device), return_features=True)\n",
    "\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, feat in enumerate(features):\n",
    "        vec = feat[0].cpu().numpy()\n",
    "        side = int(len(vec) ** 0.5)\n",
    "        img = vec[:side * side].reshape(side, side)\n",
    "        plt.subplot(1, len(features), i + 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"{title_prefix}\\nLayer {i+1}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f\"Input Label: {label}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02a4eb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1 [With BatchNorm] ---\n",
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.345695\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.212653\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 1.861607\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 1.708433\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 1.380164\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 1.286679\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 1.044925\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 0.847333\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 0.729851\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 0.744386\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 0.981424\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 0.578549\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 0.604860\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 0.597956\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 0.798302\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 0.728721\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 0.462260\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 0.695134\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 0.353075\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 0.397389\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 0.645780\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 0.470586\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 0.380432\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 0.264754\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 0.633364\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 0.348266\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 0.399998\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 0.272077\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 0.368676\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 0.159015\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 0.361899\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 0.483486\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 0.189481\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 0.422641\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 0.248517\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 0.279115\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 0.401396\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 0.295661\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 1.084285\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 0.268694\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 0.454371\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 0.299457\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 0.343471\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 0.308635\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 0.306275\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 0.509517\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 0.171316\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 0.215227\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 0.244871\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 0.264101\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 0.265398\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 0.200129\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 0.385886\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 0.182511\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 0.315230\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 0.168299\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 0.133252\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 0.431972\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 0.213078\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 0.391999\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 0.367656\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 0.211796\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 0.179372\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 0.593421\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 0.339483\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 0.147970\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 0.081322\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 0.102689\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 0.419719\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 0.205363\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 0.409600\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 0.135303\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 0.118680\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 0.122570\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 0.513380\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 0.119336\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 0.281019\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 0.289926\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 0.251344\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 0.134810\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 0.182697\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 0.242772\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 0.258010\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 0.238357\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 0.316305\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 0.287199\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 0.180759\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 0.222395\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 0.360332\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 0.179196\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 0.170726\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 0.129841\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 0.253300\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 0.382982\n",
      "===========================\n",
      "Test set: Average loss: 0.0029, Accuracy: 9513/10000 (95%)\n",
      "\n",
      "--- Epoch 1 [No BatchNorm] ---\n",
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.286790\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.285217\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.306041\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.300817\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.267937\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.053483\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 1.896723\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 1.743160\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 1.692375\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 1.516119\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 1.630093\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 1.658164\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 1.322314\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 1.322734\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 1.140810\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 1.254655\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 1.423275\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 1.220266\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 1.275587\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 0.976179\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 1.038997\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 1.017057\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 1.097548\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 1.087191\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 0.917446\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 1.019344\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 0.899935\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 1.128134\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 1.010380\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 1.150400\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 0.782347\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 0.778767\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 0.722269\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 0.734492\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 0.952723\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 0.805896\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 0.844695\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 0.675232\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 0.737632\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 0.895023\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 0.849552\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 0.697548\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 0.844714\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 0.880989\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 0.882197\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 0.670524\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 0.853340\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 0.561298\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 1.006006\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 0.556202\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 0.807817\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 0.880752\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 0.732013\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 0.638032\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 0.660910\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 0.598449\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 0.723402\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 0.989887\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 1.204572\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 0.930394\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 0.558525\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 0.492020\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 0.782438\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 0.781871\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 0.519683\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 0.615306\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 0.435964\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 0.689159\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 0.652550\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 0.384963\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 0.569983\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 0.483546\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 0.527398\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 0.833040\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 0.396170\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 0.484456\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 0.720462\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 0.497705\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 0.571536\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 0.509540\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 0.669770\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 0.291596\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 0.354129\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 0.291275\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 0.398138\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 0.389063\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 0.537569\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 0.833329\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 0.779360\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 0.572137\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 0.538964\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 0.490054\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 0.614593\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 0.463332\n",
      "===========================\n",
      "Test set: Average loss: 0.0073, Accuracy: 8718/10000 (87%)\n",
      "\n",
      "--- Epoch 2 [With BatchNorm] ---\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 0.088879\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 0.087131\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 0.310515\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 0.229619\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 0.056889\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 0.274480\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 0.307569\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 0.240470\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 0.142554\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 0.169344\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 0.274634\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 0.356928\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 0.177862\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 0.273762\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 0.361125\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.259865\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 0.045158\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.167949\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 0.236376\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.248029\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.188087\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.419954\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.203040\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.137511\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.082103\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.044516\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.115705\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.395002\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.288348\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.345127\n",
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.197385\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.131626\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.143527\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.222194\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.232105\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.247980\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.110310\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.048614\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.205026\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.133391\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.169146\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.245836\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.190447\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.211482\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.224631\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.233183\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.252086\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.094590\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.153496\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.043499\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.178837\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.163654\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.175309\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.148964\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.388276\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.181727\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.075415\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.237031\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.182616\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.253441\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.147883\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.166405\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.160766\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.052653\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.220603\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.158084\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.137653\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.070221\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.206094\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.391220\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.044316\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.141118\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.125870\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.206750\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.218501\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.104816\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.362282\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.051412\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.162036\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.300147\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.269428\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.116759\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.040336\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.209872\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.102881\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.183447\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.208122\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.352799\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.105100\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.093788\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.137829\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.224802\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.043701\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.127842\n",
      "===========================\n",
      "Test set: Average loss: 0.0018, Accuracy: 9662/10000 (97%)\n",
      "\n",
      "--- Epoch 2 [No BatchNorm] ---\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 0.429794\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 0.609236\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 0.520136\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 0.626139\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 0.433948\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 0.426176\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 0.315515\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 0.485050\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 0.146913\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 0.332196\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 0.430938\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 0.535095\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 0.834524\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 0.580992\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 0.278073\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.479272\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 0.623242\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.295177\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 0.363608\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.620767\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.203978\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.259078\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.412541\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.643084\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.407045\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.455485\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.298197\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.412294\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.330252\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.347579\n",
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.410434\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.592936\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.459244\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.294564\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.277349\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.293848\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.298654\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.339738\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.296889\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.459579\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.264063\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.266936\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.455084\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.417020\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.314038\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.272710\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.711753\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.277562\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.495525\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.357908\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.342433\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.371750\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.260975\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.267056\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.502988\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.316396\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.687164\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.262268\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.280096\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.310591\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.391689\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.269943\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.373723\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.422812\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.341949\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.356364\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.204878\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.114190\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.232820\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.201620\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.150479\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.135699\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.255391\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.261127\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.380068\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.358457\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.418685\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.250023\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.183511\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.283173\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.342823\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.302038\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.153476\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.461420\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.204254\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.273739\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.413859\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.252381\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.315802\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.179485\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.119535\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.152640\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.553747\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.374959\n",
      "===========================\n",
      "Test set: Average loss: 0.0041, Accuracy: 9289/10000 (93%)\n",
      "\n",
      "--- Epoch 3 [With BatchNorm] ---\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.025461\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.156603\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.105334\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.433383\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.277957\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.374054\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.030640\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.244619\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.119710\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.140354\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.234689\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.052025\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.417717\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.159714\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.071149\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.077166\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.041611\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.213543\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.074704\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.195662\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.027077\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.062240\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.099668\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.152213\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.164159\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.188684\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.117928\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.071806\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.112678\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.163674\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.200716\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.089229\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.279248\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.144655\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.132705\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.239719\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.027695\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.071182\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.426116\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.176885\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.239426\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.145706\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.060621\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.230501\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.025618\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.141987\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.181245\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.061751\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.258511\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.207184\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.187429\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.220247\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.148848\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.163943\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.185592\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.021283\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.228051\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.082618\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.272637\n",
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.141794\n",
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.091779\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.159581\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.040613\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.151054\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.246291\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.094715\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.115776\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.070951\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.258640\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.198522\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.130538\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.204726\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.032043\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.190402\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.039616\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.123410\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.029682\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.120830\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.148872\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.177791\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.092017\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.157892\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.061988\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.087583\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.293223\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.138265\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.095351\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.194421\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.089922\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.095462\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.223369\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.138686\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.254449\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.189867\n",
      "===========================\n",
      "Test set: Average loss: 0.0017, Accuracy: 9677/10000 (97%)\n",
      "\n",
      "--- Epoch 3 [No BatchNorm] ---\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.059048\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.214025\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.302338\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.227647\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.345210\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.177760\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.270742\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.393716\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.193746\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.125087\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.295594\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.267644\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.033830\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.145930\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.167794\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.468950\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.328110\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.198159\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.282141\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.159176\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.335097\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.121881\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.152695\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.334890\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.166298\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.127055\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.298032\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.092508\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.257229\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.354490\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.137269\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.428281\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.246004\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.392346\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.084874\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.290600\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.219109\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.219096\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.133591\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.209090\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.122895\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.316704\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.254078\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.159995\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.276299\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.370896\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.425163\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.142985\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.178789\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.262811\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.136944\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.260679\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.322815\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.468327\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.198015\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.578158\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.172036\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.092313\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.120287\n",
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.265942\n",
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.379807\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.179067\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.338253\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.144187\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.499802\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.446080\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.210888\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.165724\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.236650\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.129438\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.411996\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.331941\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.416174\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.386549\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.091034\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.564109\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.243719\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.207516\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.183589\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.193302\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.358675\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.181324\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.272997\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.066198\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.283027\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.242766\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.188305\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.287310\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.317004\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.173922\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.177548\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.328057\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.277399\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.049338\n",
      "===========================\n",
      "Test set: Average loss: 0.0037, Accuracy: 9401/10000 (94%)\n",
      "\n",
      "--- Epoch 4 [With BatchNorm] ---\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.043995\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.091554\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.196861\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.193008\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.043858\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.370664\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.110111\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.345961\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.073441\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.051363\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.082324\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.357991\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.112853\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.215536\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.192900\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.149156\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.223723\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.073260\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.116009\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.140270\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.056574\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.100423\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.084784\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.083374\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.211382\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.074417\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.139897\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.073912\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.148022\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.220407\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.026065\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.169937\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.092688\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.051478\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.023715\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.107736\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.060392\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.181281\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.150601\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.043177\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.075402\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.098352\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.217570\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.195015\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.056694\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.141783\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.083921\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.192021\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.342715\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.058947\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.128361\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.165998\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.072311\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.033636\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.252353\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.099945\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.106295\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.195565\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.049876\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.136705\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.152645\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.183420\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.182054\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.078871\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.156377\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.088373\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.031430\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.041261\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.046446\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.133909\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.078646\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.013981\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.197983\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.066402\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.118369\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.087351\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.234216\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.174012\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.038269\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.184053\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.086327\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.045447\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.090525\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.123022\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.121496\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.081507\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.263294\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.131623\n",
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.229722\n",
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.228573\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.068108\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.280096\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.133317\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.072522\n",
      "===========================\n",
      "Test set: Average loss: 0.0016, Accuracy: 9705/10000 (97%)\n",
      "\n",
      "--- Epoch 4 [No BatchNorm] ---\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.185395\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.526712\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.173835\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.248108\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.156692\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.054309\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.232874\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.289447\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.393382\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.173511\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.121555\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.251811\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.068483\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.133145\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.195914\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.140727\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.378763\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.458103\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.164956\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.169820\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.146368\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.253188\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.258304\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.218549\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.279066\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.228037\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.128675\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.419631\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.183391\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.078151\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.152837\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.167927\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.253076\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.199946\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.293193\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.024400\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.180340\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.063737\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.207405\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.351933\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.207653\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.135231\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.341984\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.279897\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.108642\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.039350\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.119166\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.151501\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.263290\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.139505\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.049537\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.126682\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.210281\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.323451\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.144585\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.158585\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.070532\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.100828\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.386451\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.134295\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.185496\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.149287\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.258933\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.136545\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.106434\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.030176\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.143857\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.128522\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.192261\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.152557\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.144930\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.504771\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.151648\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.267612\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.158792\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.228386\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.238231\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.303400\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.292892\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.197513\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.273742\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.123811\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.322354\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.176151\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.250739\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.117316\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.188153\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.237746\n",
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.392407\n",
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.142060\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.081760\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.131353\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.111705\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.357222\n",
      "===========================\n",
      "Test set: Average loss: 0.0031, Accuracy: 9499/10000 (95%)\n",
      "\n",
      "--- Epoch 5 [With BatchNorm] ---\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.028701\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.057151\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.033271\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.169265\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.123542\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.054379\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.151595\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.018865\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.199558\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.166526\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.073260\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.132113\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.066875\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.205641\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.180736\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.155487\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.072710\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.118433\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.210245\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.054960\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.023111\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.076080\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.162198\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.034096\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.134752\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.049033\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.020439\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.047446\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.065972\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.052785\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.082723\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.125069\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.095178\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.025972\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.165406\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.183398\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.028390\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.212997\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.154387\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.026043\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.070361\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.015642\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.031257\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.060410\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.051579\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.130523\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.056188\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.098767\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.095147\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.105359\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.115066\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.125927\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.054980\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.034499\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.023222\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.053552\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.251358\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.145041\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.085403\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.069993\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.107684\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.160789\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.009645\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.281817\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.170429\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.131796\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.126844\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.033851\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.229715\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.141266\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.104843\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.077194\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.076379\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.142545\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.028038\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.137670\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.219288\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.030921\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.017424\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.047420\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.085735\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.050435\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.472697\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.021666\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.124824\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.072520\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.183736\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.017917\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.087641\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.182591\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.111820\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.076189\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.181866\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.154064\n",
      "===========================\n",
      "Test set: Average loss: 0.0015, Accuracy: 9729/10000 (97%)\n",
      "\n",
      "--- Epoch 5 [No BatchNorm] ---\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.047610\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.205163\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.105857\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.165155\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.183544\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.198071\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.094122\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.146479\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.364818\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.059880\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.205093\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.226589\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.221338\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.203845\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.103588\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.163837\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.273568\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.099412\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.235420\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.187332\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.057552\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.108296\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.123047\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.068832\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.131492\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.086566\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.133063\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.049022\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.156802\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.106749\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.115001\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.138963\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.209086\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.080109\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.178992\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.191520\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.228637\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.137838\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.336327\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.232378\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.091684\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.059198\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.145189\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.227095\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.053445\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.168217\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.152727\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.326482\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.108192\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.028799\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.142300\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.222527\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.515297\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.140165\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.042410\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.286307\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.035273\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.218161\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.297414\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.140495\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.029490\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.142588\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.164582\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.107555\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.222506\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.232266\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.065983\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.194526\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.165369\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.085516\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.275465\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.254413\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.073123\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.251073\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.110618\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.206302\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.056166\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.095250\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.216113\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.166833\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.135218\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.202319\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.141540\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.244259\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.216886\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.440367\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.149697\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.052843\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.167088\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.347034\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.142615\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.251216\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.086174\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.295065\n",
      "===========================\n",
      "Test set: Average loss: 0.0030, Accuracy: 9560/10000 (96%)\n",
      "\n",
      "--- Epoch 6 [With BatchNorm] ---\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.030949\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.145602\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.060314\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.165427\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.051195\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.106224\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.076720\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.088184\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.221496\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.149854\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.220748\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.061448\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.065200\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.089069\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.109650\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.007455\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.100811\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.130420\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.035566\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.061006\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.011074\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.010227\n",
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.044999\n",
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.121277\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.056786\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.122516\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.063504\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.048434\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.041782\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.070189\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.048363\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.028141\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.053294\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.048596\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.131613\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.231803\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.019948\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.299186\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.117801\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.060123\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.245898\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.157145\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.048953\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.076417\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.267187\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.041860\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.067671\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.126952\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.044019\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.237294\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.036166\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.029250\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.028602\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.058333\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.080551\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.112089\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.107006\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.042262\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.163185\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.074772\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.112206\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.031704\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.044229\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.222880\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.033107\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.076819\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.049896\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.099406\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.439877\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.076833\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.060241\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.044385\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.098680\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.042087\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.160506\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.125215\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.071368\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.052161\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.010646\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.087833\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.067427\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.050109\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.113332\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.106717\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.036389\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.059366\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.145780\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.092783\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.092649\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.153529\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.143383\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.008229\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.104865\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.080582\n",
      "===========================\n",
      "Test set: Average loss: 0.0013, Accuracy: 9757/10000 (98%)\n",
      "\n",
      "--- Epoch 6 [No BatchNorm] ---\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.449475\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.066569\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.212591\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.053325\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.171890\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.162800\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.180837\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.032670\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.097795\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.123793\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.126918\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.137511\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.025788\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.391644\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.216944\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.283399\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.124448\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.090724\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.177567\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.155521\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.153764\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.117897\n",
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.095734\n",
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.158677\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.132686\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.093406\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.397966\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.126170\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.313972\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.223057\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.167520\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.103282\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.153030\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.159037\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.137873\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.258037\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.035958\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.149911\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.151992\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.047836\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.185959\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.028203\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.045131\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.135640\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.291928\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.239852\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.141181\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.158358\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.171889\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.039461\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.021375\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.046770\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.106232\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.104072\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.093027\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.175653\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.158648\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.156217\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.208805\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.105501\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.104890\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.130793\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.293184\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.517144\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.039301\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.172947\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.181659\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.136562\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.035589\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.041234\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.202633\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.179059\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.046849\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.151080\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.039618\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.008588\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.089044\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.111237\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.285962\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.125542\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.249328\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.305439\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.240505\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.146709\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.119869\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.310699\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.082899\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.050449\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.314538\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.192675\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.313645\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.055523\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.095916\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.164453\n",
      "===========================\n",
      "Test set: Average loss: 0.0028, Accuracy: 9541/10000 (95%)\n",
      "\n",
      "--- Epoch 7 [With BatchNorm] ---\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.035617\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.179348\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.051485\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.062187\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.027577\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.129566\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.043730\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.120338\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.145606\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.131907\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.010636\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.034619\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.003858\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.140044\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.089100\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.136639\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.160044\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.134755\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.025393\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.030159\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.035808\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.128614\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.167142\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.013828\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.015664\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.129709\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.180545\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.017110\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.067407\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.034839\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.107891\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.192041\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.016902\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.085001\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.089001\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.178283\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.162141\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.105424\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.051910\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.127680\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.066181\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.221639\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.024270\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.099656\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.150639\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.017252\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.019034\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.032044\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.061951\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.032554\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.061576\n",
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.033028\n",
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.013665\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.062578\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.127509\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.015553\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.072981\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.037098\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.018821\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.140940\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.085898\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.038575\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.057550\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.133814\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.045918\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.035202\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.180803\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.085899\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.108693\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.132628\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.010475\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.010830\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.007533\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.146455\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.029760\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.074730\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.110722\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.025115\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.142703\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.052752\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.027976\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.021166\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.042525\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.102709\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.023173\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.019189\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.191072\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.134615\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.058072\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.170744\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.022384\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.013956\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.167177\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.015839\n",
      "===========================\n",
      "Test set: Average loss: 0.0014, Accuracy: 9738/10000 (97%)\n",
      "\n",
      "--- Epoch 7 [No BatchNorm] ---\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.168838\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.126614\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.081049\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.074974\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.070885\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.159800\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.163671\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.255341\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.060694\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.187061\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.073763\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.210481\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.427798\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.164610\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.103780\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.088561\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.222466\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.067335\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.097556\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.170899\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.181494\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.110441\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.129347\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.211412\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.224510\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.085794\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.288775\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.248976\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.070734\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.098306\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.072282\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.024340\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.082323\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.054691\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.096669\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.011835\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.070303\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.015854\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.021092\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.187632\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.141267\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.063863\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.042315\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.273288\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.145370\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.057804\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.058333\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.130475\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.040081\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.158362\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.016845\n",
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.168844\n",
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.126537\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.106703\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.010409\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.024001\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.087676\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.056543\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.051931\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.009624\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.083139\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.054905\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.198986\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.036630\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.037179\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.115526\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.228983\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.032631\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.100541\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.018661\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.083983\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.121927\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.230030\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.054997\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.092295\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.021935\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.036108\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.073579\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.254555\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.078077\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.163456\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.180378\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.207856\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.128273\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.085139\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.286559\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.083908\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.045959\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.134339\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.047717\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.429689\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.101748\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.064973\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.109645\n",
      "===========================\n",
      "Test set: Average loss: 0.0026, Accuracy: 9585/10000 (96%)\n",
      "\n",
      "--- Epoch 8 [With BatchNorm] ---\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.075803\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.007692\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.072351\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.159831\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.069170\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.031451\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.094501\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.028840\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.012312\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.025950\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.062158\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.015750\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.070239\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.059173\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.114731\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.007811\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.013991\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.123487\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.065347\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.036220\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.103508\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.045366\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.111798\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.051597\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.010288\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.189670\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.074287\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.045783\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.009536\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.020527\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.045998\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.014387\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.082971\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.190618\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.131452\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.022668\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.042401\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.008601\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.060605\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.127541\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.042200\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.031692\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.103909\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.010640\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.053050\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.026548\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.042352\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.038232\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.070952\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.022509\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.104776\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.188136\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.063513\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.255598\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.099936\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.006969\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.161996\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.062504\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.007452\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.187925\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.011489\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.153905\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.072355\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.076809\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.116533\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.062787\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.135188\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.047628\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.023418\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.014855\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.137401\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.013852\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.109773\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.201243\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.026507\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.135458\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.013795\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.037821\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.145313\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.270604\n",
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.045768\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.138911\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.118354\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.055128\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.096010\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.154596\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.021053\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.026885\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.060810\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.117698\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.038722\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.071876\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.091894\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.027129\n",
      "===========================\n",
      "Test set: Average loss: 0.0013, Accuracy: 9762/10000 (98%)\n",
      "\n",
      "--- Epoch 8 [No BatchNorm] ---\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.074771\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.138185\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.031048\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.135683\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.109928\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.005016\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.239482\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.109312\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.240238\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.055217\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.229815\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.243388\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.116474\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.043652\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.105990\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.028024\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.160737\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.078088\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.013150\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.104730\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.079309\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.020756\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.021640\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.028701\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.089416\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.051293\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.246399\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.100926\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.043101\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.106053\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.197331\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.103821\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.059399\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.229915\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.143116\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.233153\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.099009\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.207249\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.110044\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.097257\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.187380\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.159110\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.131287\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.068514\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.101806\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.029775\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.163589\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.106657\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.143880\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.062716\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.113822\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.079421\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.092420\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.255040\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.127218\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.088228\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.119802\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.089164\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.200558\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.122511\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.112777\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.177361\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.101374\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.044428\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.290180\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.060924\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.188485\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.087306\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.066852\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.050697\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.365789\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.215540\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.042000\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.038094\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.145441\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.024172\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.097253\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.021183\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.098204\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.072412\n",
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.068896\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.140642\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.056392\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.092924\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.172082\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.099126\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.091707\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.215860\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.063100\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.069770\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.021532\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.075911\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.015403\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.150962\n",
      "===========================\n",
      "Test set: Average loss: 0.0026, Accuracy: 9590/10000 (96%)\n",
      "\n",
      "--- Epoch 9 [With BatchNorm] ---\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.154953\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.082761\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.066906\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.033706\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.241689\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.026252\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.092414\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.030733\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.059098\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.093207\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.213715\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.037912\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.022576\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.091113\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.029827\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.076039\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.017947\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.062755\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.053728\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.266715\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.083116\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.105422\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.021738\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.015245\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.124919\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.100835\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.101841\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.091523\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.116158\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.013544\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.123416\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.056831\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.061895\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.062014\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.086496\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.004639\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.017834\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.095683\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.022640\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.027323\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.058321\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.226840\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.041374\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.087028\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.019829\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.088082\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.019256\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.017633\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.023752\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.016033\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.036479\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.091250\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.013890\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.188888\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.058817\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.058128\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.286574\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.011075\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.033990\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.015488\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.184340\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.040715\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.012373\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.025848\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.133122\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.033581\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.061984\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.028911\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.058798\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.017908\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.043913\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.080805\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.095428\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.065229\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.011083\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.027006\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.187642\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.128937\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.009846\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.099855\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.074628\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.070521\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.043635\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.143488\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.025469\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.204068\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.065457\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.051274\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.015675\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.051105\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.170487\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.044732\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.085419\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.035466\n",
      "===========================\n",
      "Test set: Average loss: 0.0012, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "--- Epoch 9 [No BatchNorm] ---\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.098069\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.331930\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.086980\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.106152\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.279426\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.232849\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.195963\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.035702\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.013467\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.047631\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.053689\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.305328\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.137483\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.033429\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.077837\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.104793\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.090916\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.223349\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.033643\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.160561\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.100497\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.210615\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.135268\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.305675\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.109765\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.031582\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.079365\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.173661\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.053658\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.058037\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.127655\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.058568\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.118852\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.108861\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.084462\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.160615\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.097682\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.115447\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.113813\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.107143\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.100558\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.038203\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.072106\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.052533\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.194344\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.202321\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.098785\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.129161\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.059459\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.079273\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.059741\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.074335\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.064967\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.154372\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.197509\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.102226\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.108191\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.199084\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.034985\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.081682\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.136415\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.119437\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.063886\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.112993\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.261482\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.214773\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.131437\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.140447\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.075577\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.095733\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.067942\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.022010\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.034854\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.160805\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.221313\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.210917\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.046014\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.093351\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.258357\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.109491\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.084320\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.119989\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.059664\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.095561\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.288188\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.049532\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.170727\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.070262\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.132056\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.118413\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.039962\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.077909\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.053277\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.159812\n",
      "===========================\n",
      "Test set: Average loss: 0.0025, Accuracy: 9598/10000 (96%)\n"
     ]
    }
   ],
   "source": [
    "# Main Execution\n",
    "if __name__ == '__main__':\n",
    "    # Initialize models, optimizers, and loss function\n",
    "    model_bn = Net(use_batchnorm=True).to(device)\n",
    "    model_no_bn = Net(use_batchnorm=False).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_bn = torch.optim.Adam(model_bn.parameters(), \n",
    "                                    lr=0.001, \n",
    "                                    betas=(0.9, 0.999),\n",
    "                                    eps=1e-08,\n",
    "                                    weight_decay=0,\n",
    "                                    amsgrad=False)\n",
    "    \n",
    "    optimizer_no_bn = torch.optim.Adam(model_no_bn.parameters(), \n",
    "                                        lr=0.001, \n",
    "                                        betas=(0.9, 0.999),\n",
    "                                        eps=1e-08,\n",
    "                                        weight_decay=0,\n",
    "                                        amsgrad=False)\n",
    "\n",
    "    for epoch in range(1, 10):  \n",
    "        print(f\"\\n--- Epoch {epoch} [With BatchNorm] ---\")\n",
    "        train(model_bn, optimizer_bn, criterion, epoch)\n",
    "        test(model_bn, criterion)\n",
    "\n",
    "        print(f\"\\n--- Epoch {epoch} [No BatchNorm] ---\")\n",
    "        train(model_no_bn, optimizer_no_bn, criterion, epoch)\n",
    "        test(model_no_bn, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781aea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Test Image Label: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_img, sample_label = next(iter(sample_loader))\n",
    "print(f\"\\nSelected Test Image Label: {sample_label.item()}\")\n",
    "visualize_features(model_bn, sample_img[0], sample_label.item(), \"W/ BatchNorm\")\n",
    "visualize_features(model_no_bn, sample_img[0], sample_label.item(), \"w/o BatchNorm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
